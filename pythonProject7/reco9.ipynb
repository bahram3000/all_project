{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "x = load_breast_cancer().data\n",
    "y = load_breast_cancer().target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n        1.189e-01],\n       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n        8.902e-02],\n       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n        8.758e-02],\n       ...,\n       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n        7.820e-02],\n       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n        1.240e-01],\n       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n        7.039e-02]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data = pd.DataFrame(x, columns=load_breast_cancer().feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data['labels'] = y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0          17.99         10.38          122.80     1001.0          0.11840   \n1          20.57         17.77          132.90     1326.0          0.08474   \n2          19.69         21.25          130.00     1203.0          0.10960   \n3          11.42         20.38           77.58      386.1          0.14250   \n4          20.29         14.34          135.10     1297.0          0.10030   \n..           ...           ...             ...        ...              ...   \n564        21.56         22.39          142.00     1479.0          0.11100   \n565        20.13         28.25          131.20     1261.0          0.09780   \n566        16.60         28.08          108.30      858.1          0.08455   \n567        20.60         29.33          140.10     1265.0          0.11780   \n568         7.76         24.54           47.92      181.0          0.05263   \n\n     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0             0.27760         0.30010              0.14710         0.2419   \n1             0.07864         0.08690              0.07017         0.1812   \n2             0.15990         0.19740              0.12790         0.2069   \n3             0.28390         0.24140              0.10520         0.2597   \n4             0.13280         0.19800              0.10430         0.1809   \n..                ...             ...                  ...            ...   \n564           0.11590         0.24390              0.13890         0.1726   \n565           0.10340         0.14400              0.09791         0.1752   \n566           0.10230         0.09251              0.05302         0.1590   \n567           0.27700         0.35140              0.15200         0.2397   \n568           0.04362         0.00000              0.00000         0.1587   \n\n     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n0                   0.07871  ...          17.33           184.60      2019.0   \n1                   0.05667  ...          23.41           158.80      1956.0   \n2                   0.05999  ...          25.53           152.50      1709.0   \n3                   0.09744  ...          26.50            98.87       567.7   \n4                   0.05883  ...          16.67           152.20      1575.0   \n..                      ...  ...            ...              ...         ...   \n564                 0.05623  ...          26.40           166.10      2027.0   \n565                 0.05533  ...          38.25           155.00      1731.0   \n566                 0.05648  ...          34.12           126.70      1124.0   \n567                 0.07016  ...          39.42           184.60      1821.0   \n568                 0.05884  ...          30.37            59.16       268.6   \n\n     worst smoothness  worst compactness  worst concavity  \\\n0             0.16220            0.66560           0.7119   \n1             0.12380            0.18660           0.2416   \n2             0.14440            0.42450           0.4504   \n3             0.20980            0.86630           0.6869   \n4             0.13740            0.20500           0.4000   \n..                ...                ...              ...   \n564           0.14100            0.21130           0.4107   \n565           0.11660            0.19220           0.3215   \n566           0.11390            0.30940           0.3403   \n567           0.16500            0.86810           0.9387   \n568           0.08996            0.06444           0.0000   \n\n     worst concave points  worst symmetry  worst fractal dimension  labels  \n0                  0.2654          0.4601                  0.11890       0  \n1                  0.1860          0.2750                  0.08902       0  \n2                  0.2430          0.3613                  0.08758       0  \n3                  0.2575          0.6638                  0.17300       0  \n4                  0.1625          0.2364                  0.07678       0  \n..                    ...             ...                      ...     ...  \n564                0.2216          0.2060                  0.07115       0  \n565                0.1628          0.2572                  0.06637       0  \n566                0.1418          0.2218                  0.07820       0  \n567                0.2650          0.4087                  0.12400       0  \n568                0.0000          0.2871                  0.07039       1  \n\n[569 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>0.1726</td>\n      <td>0.05623</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.1752</td>\n      <td>0.05533</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.1590</td>\n      <td>0.05648</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.2397</td>\n      <td>0.07016</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1587</td>\n      <td>0.05884</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as k"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "NN = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "NN.add(Dense(13, activation='relu', input_shape=(30,)))\n",
    "NN.add(Dense(1, activation='sigmoid', ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "NN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 0.8008 - accuracy: 0.3869\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.3945\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.3995\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.4121\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.4422\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.4673\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.5025\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.5578\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.6106\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.6709\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7337\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8291\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8794\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.9221\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.9296\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.9372\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.9422\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.9447\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.9472\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.9548\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.9548\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.9598\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9598\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.9623\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9623\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9623\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9623\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9648\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9673\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9673\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9673\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1752 - accuracy: 0.9673\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9673\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9698\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9698\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9724\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9749\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9749\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9749\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9749\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9749\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9774\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.9774\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9799\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9799\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9799\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9799\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9799\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9799\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9799\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9799\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9799\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9799\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9799\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9799\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9799\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9799\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9799\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9799\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9799\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9799\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9799\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9799\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9799\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9799\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9799\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9799\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9799\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9799\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9799\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9799\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9799\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9799\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9799\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9799\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9799\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9799\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9799\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9799\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9799\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9799\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9799\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9799\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9799\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9799\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9799\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9824\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9824\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9824\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9824\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9824\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9824\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9824\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9824\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9824\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9824\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9824\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9824\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9849\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9874\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9874\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9874\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9874\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9874\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9874\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9874\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9874\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9874\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9874\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9874\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9874\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9874\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9874\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9899\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9899\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9899\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9899\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9899\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9899\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9899\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9899\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9899\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9899\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9899\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9899\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9899\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9899\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9899\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9899\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9899\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9899\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9899\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9899\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9899\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9899\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9899\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9899\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9899\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9899\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9899\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9899\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9899\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9899\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9899\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9899\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9899\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9899\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9899\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9899\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x26c8fcc1600>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.fit(x_train, y_train, batch_size=100, epochs=150)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.07677063345909119, 0.9824561476707458]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n        ...,\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n 'target': array([0, 1, 2, ..., 8, 9, 8]),\n 'frame': None,\n 'feature_names': ['pixel_0_0',\n  'pixel_0_1',\n  'pixel_0_2',\n  'pixel_0_3',\n  'pixel_0_4',\n  'pixel_0_5',\n  'pixel_0_6',\n  'pixel_0_7',\n  'pixel_1_0',\n  'pixel_1_1',\n  'pixel_1_2',\n  'pixel_1_3',\n  'pixel_1_4',\n  'pixel_1_5',\n  'pixel_1_6',\n  'pixel_1_7',\n  'pixel_2_0',\n  'pixel_2_1',\n  'pixel_2_2',\n  'pixel_2_3',\n  'pixel_2_4',\n  'pixel_2_5',\n  'pixel_2_6',\n  'pixel_2_7',\n  'pixel_3_0',\n  'pixel_3_1',\n  'pixel_3_2',\n  'pixel_3_3',\n  'pixel_3_4',\n  'pixel_3_5',\n  'pixel_3_6',\n  'pixel_3_7',\n  'pixel_4_0',\n  'pixel_4_1',\n  'pixel_4_2',\n  'pixel_4_3',\n  'pixel_4_4',\n  'pixel_4_5',\n  'pixel_4_6',\n  'pixel_4_7',\n  'pixel_5_0',\n  'pixel_5_1',\n  'pixel_5_2',\n  'pixel_5_3',\n  'pixel_5_4',\n  'pixel_5_5',\n  'pixel_5_6',\n  'pixel_5_7',\n  'pixel_6_0',\n  'pixel_6_1',\n  'pixel_6_2',\n  'pixel_6_3',\n  'pixel_6_4',\n  'pixel_6_5',\n  'pixel_6_6',\n  'pixel_6_7',\n  'pixel_7_0',\n  'pixel_7_1',\n  'pixel_7_2',\n  'pixel_7_3',\n  'pixel_7_4',\n  'pixel_7_5',\n  'pixel_7_6',\n  'pixel_7_7'],\n 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n         ...,\n         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n \n        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n         ...,\n         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n \n        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n         ...,\n         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n \n        ...,\n \n        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n         ...,\n         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n \n        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n         ...,\n         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n \n        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n         ...,\n         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x = load_digits().data\n",
    "y = load_digits().target\n",
    "x_image = load_digits().images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n        ...,\n        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n        ...,\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n        ...,\n        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n\n       ...,\n\n       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n        ...,\n        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n\n       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n        ...,\n        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n\n       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n        ...,\n        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "16.0"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(1797, 8, 8)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_image.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2b43031e5c0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_image[0], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_image, y, train_size=0.7, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "x_train = x_train / 16\n",
    "x_test = x_test / 16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "mlp=Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "mlp.add(Flatten(input_shape=(8,8)))\n",
    "mlp.add(Dense(200,activation='relu'))\n",
    "mlp.add(Dense(10,activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "mlp.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 2.2595 - accuracy: 0.2092\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0117 - accuracy: 0.5648\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7772 - accuracy: 0.7924\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5487 - accuracy: 0.8544\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3315 - accuracy: 0.8791\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1350 - accuracy: 0.8902\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9636 - accuracy: 0.8958\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8202 - accuracy: 0.9093\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.9133\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.9157\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.5368 - accuracy: 0.9244\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.9252\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.9316\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.9356\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3620 - accuracy: 0.9387\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.9419\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.9443\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.9411\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2740 - accuracy: 0.9467\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.9499\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9539\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9547\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9610\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 0.9594\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9634\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9634\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9650\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9698\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1684 - accuracy: 0.9698\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9682\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9714\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9722\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9714\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9737\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9737\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9745\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9761\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9777\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9777\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9793\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9777\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9793\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9793\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9801\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9809\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9809\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9809\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9817\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9809\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9809\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9849\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9833\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9841\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9841\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9841\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9865\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9849\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9865\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9873\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9857\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9881\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9873\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9881\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9889\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9905\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9897\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9905\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9905\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9912\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9905\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9912\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9928\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9912\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9912\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9928\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9928\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9936\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9952\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9936\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9936\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9952\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9952\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9944\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9960\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9960\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9944\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9952\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9952\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9952\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9960\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9960\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9952\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9968\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9960\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9960\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9968\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9960\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x2b433885d20>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train,batch_size=180,epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.    , 0.    , 0.8125, 1.    , 1.    , 1.    , 0.5   , 0.    ],\n       [0.    , 0.125 , 1.    , 0.8125, 0.5   , 0.25  , 0.0625, 0.    ],\n       [0.    , 0.4375, 1.    , 0.0625, 0.    , 0.    , 0.    , 0.    ],\n       [0.    , 0.6875, 0.9375, 0.75  , 0.3125, 0.    , 0.    , 0.    ],\n       [0.    , 0.3125, 1.    , 1.    , 1.    , 0.1875, 0.    , 0.    ],\n       [0.    , 0.    , 0.    , 0.375 , 1.    , 0.125 , 0.    , 0.    ],\n       [0.    , 0.    , 0.1875, 0.9375, 0.5625, 0.    , 0.    , 0.    ],\n       [0.    , 0.    , 0.6875, 0.875 , 0.    , 0.    , 0.    , 0.    ]])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[4.2087407e-07, 2.1430369e-06, 3.7922838e-08, ..., 1.6767796e-04,\n        4.9988644e-06, 6.3618104e-06],\n       [1.8444585e-07, 5.0334227e-03, 2.8842201e-06, ..., 9.9307090e-01,\n        3.6096717e-06, 1.4767290e-06],\n       [9.9909854e-01, 2.2376136e-09, 2.2757129e-06, ..., 2.4810043e-07,\n        2.0651082e-06, 9.0425274e-06],\n       ...,\n       [5.0732951e-10, 2.0151412e-09, 2.0618258e-05, ..., 3.8570812e-07,\n        2.0636060e-07, 2.8811830e-05],\n       [1.5455067e-01, 8.1995323e-02, 4.5924081e-04, ..., 9.6415992e-05,\n        5.2054065e-01, 4.0862896e-02],\n       [2.8898855e-06, 3.0018576e-08, 1.3628022e-08, ..., 1.0803946e-06,\n        3.2244861e-05, 2.6975104e-04]], dtype=float32)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pr=mlp.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pr[0,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 7, 0, 8, 6, 8, 6, 7, 0, 3, 2, 6, 5, 1, 0, 5, 2, 9, 4, 0, 6, 1,\n       9, 1, 5, 9, 9, 9, 7, 8, 7, 7, 6, 5, 2, 9, 6, 5, 4, 0, 0, 2, 8, 7,\n       6, 4, 7, 7, 3, 0, 6, 6, 4, 2, 9, 4, 3, 5, 3, 7, 1, 5, 9, 1, 0, 8,\n       0, 5, 4, 9, 7, 5, 6, 7, 2, 8, 6, 4, 4, 0, 9, 3, 8, 7, 7, 4, 6, 3,\n       4, 6, 4, 0, 3, 1, 3, 6, 2, 7, 9, 9, 9, 0, 6, 5, 2, 4, 2, 8, 8, 4,\n       1, 9, 5, 4, 1, 8, 4, 7, 4, 6, 5, 8, 4, 1, 6, 9, 3, 7, 3, 4, 7, 3,\n       4, 0, 5, 5, 1, 1, 0, 9, 4, 9, 6, 3, 6, 0, 4, 6, 8, 8, 2, 2, 5, 9,\n       7, 0, 6, 4, 4, 4, 9, 6, 1, 8, 7, 6, 0, 6, 6, 1, 2, 9, 9, 3, 0, 8,\n       5, 2, 9, 8, 8, 6, 1, 2, 5, 2, 7, 6, 8, 7, 9, 5, 0, 4, 0, 0, 7, 3,\n       9, 4, 8, 2, 2, 6, 4, 0, 5, 5, 4, 5, 1, 0, 5, 4, 8, 8, 8, 1, 3, 4,\n       4, 2, 9, 4, 4, 3, 7, 5, 1, 2, 1, 1, 7, 2, 5, 7, 3, 9, 6, 4, 3, 0,\n       5, 4, 7, 8, 6, 1, 1, 4, 6, 5, 8, 1, 4, 8, 4, 2, 4, 0, 3, 0, 8, 4,\n       0, 6, 9, 0, 8, 0, 4, 5, 8, 6, 1, 3, 5, 7, 4, 3, 6, 9, 2, 6, 8, 6,\n       7, 0, 8, 2, 1, 9, 2, 8, 0, 8, 1, 0, 9, 6, 5, 9, 2, 6, 2, 9, 4, 0,\n       0, 5, 2, 9, 1, 9, 0, 4, 3, 3, 8, 0, 4, 6, 7, 7, 5, 3, 9, 5, 0, 7,\n       3, 0, 1, 8, 7, 9, 4, 4, 7, 3, 7, 4, 7, 4, 7, 1, 7, 0, 8, 6, 4, 3,\n       4, 4, 3, 7, 1, 7, 3, 8, 6, 0, 9, 1, 2, 1, 9, 7, 5, 4, 8, 7, 1, 7,\n       6, 2, 1, 3, 7, 3, 7, 0, 9, 7, 4, 1, 6, 4, 2, 7, 3, 7, 1, 6, 3, 2,\n       1, 8, 4, 7, 4, 0, 9, 1, 5, 2, 1, 9, 8, 5, 8, 2, 6, 1, 9, 5, 5, 2,\n       4, 3, 3, 1, 7, 6, 5, 7, 1, 9, 0, 1, 3, 4, 4, 0, 4, 2, 2, 5, 0, 0,\n       2, 2, 0, 4, 1, 2, 9, 0, 6, 4, 1, 0, 6, 4, 8, 7, 9, 5, 2, 0, 9, 3,\n       6, 4, 7, 6, 4, 2, 0, 2, 3, 1, 2, 5, 0, 8, 1, 8, 6, 0, 1, 0, 5, 6,\n       7, 6, 1, 9, 8, 7, 6, 8, 9, 5, 9, 0, 3, 0, 9, 5, 8, 8, 1, 2, 6, 9,\n       3, 8, 7, 6, 8, 7, 4, 7, 9, 7, 0, 3, 3, 1, 1, 8, 6, 6, 3, 5, 7, 7,\n       9, 8, 2, 6, 4, 8, 9, 6, 0, 3, 8, 5], dtype=int64)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=[]\n",
    "for i in pr:\n",
    "    out.append(np.argmax(i))\n",
    "out=np.array(out)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x2b433501300>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(out,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9907407407407407"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(out==y_test)/len(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.05505385249853134, 0.9907407164573669]"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.evaluate(x_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n           37.88      , -122.23      ],\n        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n           37.86      , -122.22      ],\n        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n           37.85      , -122.24      ],\n        ...,\n        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n           39.43      , -121.22      ],\n        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n           39.43      , -121.32      ],\n        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n           39.37      , -121.24      ]]),\n 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n 'frame': None,\n 'target_names': ['MedHouseVal'],\n 'feature_names': ['MedInc',\n  'HouseAge',\n  'AveRooms',\n  'AveBedrms',\n  'Population',\n  'AveOccup',\n  'Latitude',\n  'Longitude'],\n 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}