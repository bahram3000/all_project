{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "x_train = x_train / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_test = x_test / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 28, 28)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "x_train_c = x_train.reshape(60000, 28 * 28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=49)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "x_train = pca.fit_transform(x_train_c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 4.86010152e-01, -1.22617358e+00, -9.61335362e-02, ...,\n         5.17922160e-01, -2.57200835e-01,  1.90618354e-01],\n       [ 3.96752304e+00, -1.15630211e+00,  2.33858651e+00, ...,\n        -1.02201061e+00, -6.79083136e-01,  5.02038079e-01],\n       [-2.03331796e-01,  1.53793393e+00, -7.39253919e-01, ...,\n         2.37490112e-02,  2.18428914e-01, -6.83674541e-01],\n       ...,\n       [-6.98248822e-01,  6.27757690e-01, -1.01024738e+00, ...,\n        -1.47661853e-01, -3.50114668e-03,  3.56032846e-01],\n       [ 5.12180675e-01, -2.19291624e-02,  2.01513205e+00, ...,\n        -3.44102700e-03,  1.99526580e-02,  1.60667604e-01],\n       [-6.80140990e-01, -9.69364794e-02,  2.18046625e+00, ...,\n        -1.24481697e-01, -3.57470493e-01,  6.96672310e-01]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "x_test = pca.transform(x_test.reshape(10000, 28 * 28))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [Dense(49, activation='relu', input_dim=49), Dense(10, activation='relu'), Dense(10, activation='softmax')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class loghistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.weights1 = []\n",
    "        self.weights2 = []\n",
    "\n",
    "    def on_batch_end(self, batch ,logs={}):\n",
    "        self.weights1.append(self.model.layer[1].get_weights())\n",
    "        self.weights2.append(self.model.layer[2].get_weights())\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('acc'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "import time\n",
    "name=f'model{int(time.time())}'\n",
    "tensor_board=TensorBoard(log_dir='C:\\\\Users\\\\ADMIN\\\\Desktop'+name,histogram_freq=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0360 - accuracy: 0.9895\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0359 - accuracy: 0.9896\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0358 - accuracy: 0.9898\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0359 - accuracy: 0.9895\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0358 - accuracy: 0.9897\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0358 - accuracy: 0.9897\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0358 - accuracy: 0.9897\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0356 - accuracy: 0.9896\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0355 - accuracy: 0.9899\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0355 - accuracy: 0.9898\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0355 - accuracy: 0.9898\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0353 - accuracy: 0.9898\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0355 - accuracy: 0.9899\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0354 - accuracy: 0.9898\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0353 - accuracy: 0.9898\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 0.9900\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 0.9900\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0351 - accuracy: 0.9898\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0351 - accuracy: 0.9901\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0350 - accuracy: 0.9901\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0349 - accuracy: 0.9901\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0349 - accuracy: 0.9901\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0348 - accuracy: 0.9901\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0348 - accuracy: 0.9900\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0348 - accuracy: 0.9901\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0347 - accuracy: 0.9900\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0347 - accuracy: 0.9900\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0345 - accuracy: 0.9903\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0345 - accuracy: 0.9902\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0345 - accuracy: 0.9901\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9903\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0344 - accuracy: 0.9902\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0343 - accuracy: 0.9901\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0343 - accuracy: 0.9902\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9901\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0342 - accuracy: 0.9904\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0342 - accuracy: 0.9904\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0342 - accuracy: 0.9904\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0340 - accuracy: 0.9904\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0339 - accuracy: 0.9905\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0340 - accuracy: 0.9904\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0339 - accuracy: 0.9903\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0339 - accuracy: 0.9904\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0337 - accuracy: 0.9905\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0337 - accuracy: 0.9905\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0338 - accuracy: 0.9904\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0337 - accuracy: 0.9905\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9905\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9906\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0335 - accuracy: 0.9907\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9904\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0335 - accuracy: 0.9906\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0334 - accuracy: 0.9907\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 0.9908\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 0.9906\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0332 - accuracy: 0.9908\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0332 - accuracy: 0.9909\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0332 - accuracy: 0.9907\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0331 - accuracy: 0.9908\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0331 - accuracy: 0.9909\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0330 - accuracy: 0.9909\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9907\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0330 - accuracy: 0.9908\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 0.9907\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0328 - accuracy: 0.9910\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0328 - accuracy: 0.9910\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0328 - accuracy: 0.9910\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0328 - accuracy: 0.9909\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0327 - accuracy: 0.9909\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9911\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0326 - accuracy: 0.9911\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9908\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9908\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0325 - accuracy: 0.9909\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0324 - accuracy: 0.9911\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0324 - accuracy: 0.9912\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0324 - accuracy: 0.9911\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0323 - accuracy: 0.9911\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9910\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 0.9912\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9912\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0321 - accuracy: 0.9909\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0321 - accuracy: 0.9912\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0320 - accuracy: 0.9912\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0320 - accuracy: 0.9913\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0320 - accuracy: 0.9910\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0319 - accuracy: 0.9913\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0319 - accuracy: 0.9911\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0319 - accuracy: 0.9911\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0318 - accuracy: 0.9913\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 0.9911\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 0.9913\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0316 - accuracy: 0.9915\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0316 - accuracy: 0.9912\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0315 - accuracy: 0.9914\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0315 - accuracy: 0.9915\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9913\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 0.9913\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 0.9917\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0314 - accuracy: 0.9916\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9916\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0313 - accuracy: 0.9913\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0312 - accuracy: 0.9914\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9915\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9913\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9913\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 0.9915\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9916\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0310 - accuracy: 0.9915\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0310 - accuracy: 0.9914\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0309 - accuracy: 0.9916\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0309 - accuracy: 0.9914\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0309 - accuracy: 0.9916\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0308 - accuracy: 0.9916\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0308 - accuracy: 0.9914\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0308 - accuracy: 0.9914\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 0.9915\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0306 - accuracy: 0.9916\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0306 - accuracy: 0.9915\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0307 - accuracy: 0.9916\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0306 - accuracy: 0.9916\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0307 - accuracy: 0.9914\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0307 - accuracy: 0.9916\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0305 - accuracy: 0.9916\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0304 - accuracy: 0.9915\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9918\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0303 - accuracy: 0.9917\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9916\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 0.9917\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.9918\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0302 - accuracy: 0.9918\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0301 - accuracy: 0.9917\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0301 - accuracy: 0.9918\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0300 - accuracy: 0.9920\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9916\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0300 - accuracy: 0.9916\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0300 - accuracy: 0.9918\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0300 - accuracy: 0.9918\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9918\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9919\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0298 - accuracy: 0.9918\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0298 - accuracy: 0.9919\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0298 - accuracy: 0.9919\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0296 - accuracy: 0.9919\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.9921\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0297 - accuracy: 0.9919\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 0.9919\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.9919\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9920\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x14ba32a0580>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=6000, epochs=150,callbacks=[tensor_board])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.12258794158697128, 0.9728000164031982]"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'dense/kernel:0' shape=(49, 49) dtype=float32, numpy=\n array([[ 0.5488598 , -0.49532345, -0.1925753 , ...,  0.20640631,\n          0.41230944, -0.14865722],\n        [-0.27706805,  0.25002897, -0.419819  , ..., -0.24312058,\n         -0.39639348, -0.03478944],\n        [-0.63690805, -0.16212176,  0.72813267, ...,  0.8573734 ,\n         -0.16182518,  0.05193463],\n        ...,\n        [ 0.58024   ,  0.0223763 , -0.1561424 , ...,  0.07366052,\n          0.74947834, -0.02042647],\n        [ 0.06839023, -0.24281225, -0.6466002 , ...,  0.06912815,\n          0.79956126,  0.05827476],\n        [ 0.863233  ,  0.09757795, -0.08282947, ..., -0.2948319 ,\n          0.3066127 , -0.07679905]], dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(49,) dtype=float32, numpy=\n array([ 2.86061503e-02, -2.53681690e-01,  2.73197651e-01,  2.25662798e-01,\n         4.39091802e-01,  2.81417519e-01,  1.97148263e-01,  5.72479844e-01,\n         9.57983732e-01,  1.11763412e-02, -6.99834168e-01,  8.30893219e-02,\n         3.67144942e-01, -2.85054386e-01,  6.21951044e-01,  4.90927696e-02,\n         1.70587301e-01,  1.38038650e-01, -7.76872933e-01, -3.11455369e-01,\n         2.04267994e-01,  7.91151524e-01,  1.75179377e-01,  3.73544753e-01,\n         4.42492038e-01, -1.75003648e-01,  2.11523607e-01,  1.88995451e-01,\n        -4.74811792e-02,  4.62753102e-02,  4.67655987e-01, -2.01016054e-01,\n         5.39296448e-01,  2.99777859e-03,  3.89402390e-01,  6.28030479e-01,\n         3.04080158e-01, -3.10152888e-01, -3.37792165e-03,  4.19055581e-01,\n         2.28284314e-01,  7.01951861e-01, -1.12039391e-02, -1.23024456e-01,\n         2.19570383e-01,  2.93951988e-01, -3.36659282e-01,  9.06950445e-05,\n         4.15995151e-01], dtype=float32)>,\n <tf.Variable 'dense_1/kernel:0' shape=(49, 10) dtype=float32, numpy=\n array([[-0.11523119,  0.74989414,  0.4867244 ,  0.10672428,  0.70857257,\n         -0.15049213,  0.37308055,  0.2681915 , -0.42725733,  1.0608884 ],\n        [ 0.72385377, -1.247887  ,  0.5411213 ,  0.16477267,  0.3617893 ,\n         -0.2727737 ,  0.32806006, -0.01248247, -0.52733225,  0.3524414 ],\n        [-0.30899724,  0.71733034,  0.01521957, -0.83580655, -0.11362807,\n          0.16221197,  0.7763829 , -0.17205137,  0.5705083 ,  0.5456325 ],\n        [-0.8464556 ,  0.03504104,  0.17504364,  0.71113664,  0.46226028,\n          0.682038  ,  0.5079564 ,  0.12735783, -0.19697438, -0.5585122 ],\n        [ 0.2762116 ,  0.8439265 ,  0.33712485, -1.2095174 , -0.17419289,\n          0.13946502,  0.14711182,  0.4732441 ,  0.68180895,  0.5579827 ],\n        [ 0.2343097 ,  0.5049208 ,  0.6808184 ,  0.22736323,  0.14680737,\n          0.2668972 , -0.7924594 ,  0.51938015, -0.5769116 , -0.5299431 ],\n        [-0.30745247,  0.38900828,  0.3916732 ,  0.71308553,  0.9092859 ,\n         -0.10837077,  0.48933098,  0.06582701,  0.14245836, -0.99114233],\n        [-0.48213032, -0.06530164, -0.5694366 ,  0.5859642 , -0.1651227 ,\n          0.60471195,  0.16188103,  0.26677412,  0.801873  ,  0.6643758 ],\n        [-0.30054218, -0.3995869 , -0.41850019,  0.6935679 , -0.3564312 ,\n          0.31983015, -0.5630406 ,  0.69701904,  0.10232774,  0.59459573],\n        [ 0.28033063,  0.5230103 ,  0.3776445 , -0.09541139,  0.5209403 ,\n         -0.7235006 ,  0.33251187,  0.22997972, -0.63894886, -0.26621467],\n        [ 0.33804703,  0.27790993, -0.28754452,  0.9659055 , -0.7397116 ,\n          0.63369906, -0.77570146,  0.27308837,  0.07398554, -0.6770426 ],\n        [-0.3602435 , -0.41325352, -0.08695398,  0.6661703 ,  0.13399844,\n          0.94865805,  0.30693662,  0.20887323, -0.49811175, -0.34326363],\n        [-0.20528832, -0.6148676 ,  0.07618877,  0.7886893 ,  0.23688357,\n          0.58291507, -1.0544237 , -0.08156718,  0.21454899,  0.29202822],\n        [ 0.22476164,  0.33766967, -0.51246536,  0.7676785 ,  0.06082376,\n         -0.08186916, -0.75835615,  0.59792876, -0.09734324, -0.20358084],\n        [ 0.21230328, -0.7114051 ,  0.89480233, -0.30737728, -0.13447927,\n         -0.03783516,  0.2250414 ,  0.46495125, -0.09573676, -0.01798477],\n        [ 0.16831456,  0.7127604 , -0.6394222 ,  0.5345459 , -0.05751773,\n         -0.15718283,  0.04640725,  0.5403084 ,  0.63804346,  0.41172296],\n        [ 0.43975377,  0.2921067 ,  0.30036253,  0.9149723 , -0.2829437 ,\n          0.25812164,  0.36130685, -0.43561804,  0.35948738, -0.8480769 ],\n        [ 0.11690807, -0.17391479, -0.1193061 ,  0.25606304,  0.85500455,\n          0.806736  ,  0.6806784 , -0.8725962 , -0.26192048,  0.27706134],\n        [-0.04557033,  0.75939417, -1.0077293 ,  0.7426903 ,  0.02934753,\n         -0.3762126 , -1.0977196 , -0.40198445,  0.9433402 ,  0.80223984],\n        [ 0.39267638,  0.03729236, -0.2568747 ,  0.0645695 ,  0.603329  ,\n         -0.7343747 ,  0.6498765 ,  0.2491305 ,  0.46854198,  0.11620836],\n        [ 0.5318479 , -0.06337791,  0.07586922,  0.5872908 , -0.5942826 ,\n          0.6938231 , -0.01273923, -0.44888517,  0.4191366 , -0.2440634 ],\n        [ 0.48571622,  0.06809971, -0.01894148,  0.18291637, -0.49172258,\n          0.35008335,  0.23596175,  0.48289737, -0.6816155 , -1.0786813 ],\n        [ 0.4821134 ,  0.6243138 , -0.06493519, -0.20221773,  0.10038006,\n          0.5243329 , -0.3247746 ,  0.90287936,  0.76113   ,  0.6132198 ],\n        [-0.10610968, -0.40045708, -0.09783494,  0.4918939 ,  0.12723605,\n         -0.34161457,  0.45505932, -0.79961866,  0.84057164,  0.47064802],\n        [ 0.26973853, -0.01331284,  0.13912642, -0.50673777, -0.73590475,\n          1.0900517 ,  0.29115355,  0.13841848,  0.53821284, -0.1947915 ],\n        [ 0.15486519, -0.04832573,  0.76099324, -0.03450792, -0.0350772 ,\n         -0.0381346 ,  0.4184358 , -0.66018516,  0.89187783,  0.7109343 ],\n        [ 0.5403509 ,  0.273381  ,  0.33161214, -0.19784756,  0.84181505,\n          0.6673332 ,  0.11407552,  0.69461197, -0.2831134 ,  0.64888227],\n        [-0.21507095,  0.1997893 , -0.739687  ,  0.2433987 ,  0.00536519,\n         -0.12081501, -0.21883476,  0.6997855 , -0.06655935,  1.1693553 ],\n        [ 0.011591  ,  0.45651978,  0.22076721,  0.27364358,  0.06223401,\n         -0.11932169, -0.34949946,  0.9157648 , -1.1558144 ,  0.08681614],\n        [ 0.5141838 , -0.5591757 ,  0.20452335,  0.68330497,  1.124141  ,\n          0.10638725, -0.7285497 , -0.19856764,  0.44588318,  0.43037578],\n        [ 0.53010887, -0.72202617, -0.1430093 , -0.25117037, -0.28369206,\n          0.3533924 ,  1.087832  , -0.7416794 ,  0.4097122 ,  0.49623412],\n        [ 0.3018175 ,  0.27623802, -0.27902377, -0.21968329,  0.48065507,\n         -0.80129635,  0.37604922,  0.9295686 ,  0.08377022, -0.06890452],\n        [-0.29874447,  0.08192036, -0.38811356,  0.8843518 ,  0.33593237,\n          0.5988995 ,  0.24565189,  0.42627868,  0.30663094, -0.478902  ],\n        [-0.06994772,  1.0788432 ,  0.07267533,  0.30313197,  0.26564527,\n         -0.5441568 ,  0.8514332 , -0.61807317, -0.12676218, -0.7771933 ],\n        [ 0.29292372, -0.15816362,  0.61461514, -0.3129203 ,  0.7315723 ,\n         -0.5862373 ,  0.05627435,  0.17754522, -0.5010649 ,  0.43518054],\n        [ 0.15327127, -0.20313941,  0.12804106,  0.15758857, -0.3931847 ,\n          0.9457348 ,  0.11991976,  0.4639856 ,  0.1520161 ,  0.43069756],\n        [ 0.26239455, -0.7637088 ,  0.19472805,  0.2432851 , -0.01347096,\n          0.2957286 , -0.907485  , -0.19529094, -0.13798264,  0.00599864],\n        [ 0.8030082 ,  0.36491612, -0.13973442, -0.5464585 ,  0.55275744,\n          0.1957051 ,  0.6879884 , -0.56985545, -0.18342273,  0.3810998 ],\n        [ 0.50269955, -0.44216916,  0.21272345,  0.706942  ,  0.9695108 ,\n         -0.3114437 ,  0.21700181,  0.7464569 , -0.05929678, -0.28764036],\n        [ 0.16930515,  0.20706157,  0.57989365, -1.1375982 , -0.05144952,\n          0.48637524,  0.09601541, -0.12574247,  0.46961805,  0.58912826],\n        [ 0.5703397 ,  0.94003576,  0.50204873, -0.15406497, -0.29137245,\n         -0.539228  , -0.15488291,  0.25004017,  0.42799258,  0.39778394],\n        [ 0.06191554,  0.17992523,  0.58478904,  0.1280305 ,  0.4971792 ,\n          0.22753707, -1.3606417 , -0.39265662, -0.5572167 ,  0.8954716 ],\n        [ 0.18075   ,  0.66248816,  0.2547736 , -0.04026813, -0.20096856,\n         -0.32152328,  0.13340278, -0.6078787 ,  0.9456447 ,  0.06891274],\n        [-0.4160442 ,  0.2023628 ,  0.4711637 ,  0.5769162 ,  0.53377545,\n         -0.56334466, -0.1157601 ,  0.7643675 ,  0.467192  , -0.19027556],\n        [-0.6418563 , -0.7994236 , -0.21709314,  0.74357104,  0.35366026,\n          0.63773483,  0.40025243,  0.41125977, -0.10930327,  0.15087548],\n        [-0.12601341,  0.7987763 ,  0.07970108,  0.01005756, -0.39649636,\n         -0.27575552,  0.20341338,  0.5400827 ,  0.6492478 ,  0.71018106],\n        [ 0.0614295 ,  0.17297362,  0.29330668,  0.0853591 , -0.44798335,\n          0.45260903, -0.07757355,  0.90099204, -1.1447283 , -0.46496317],\n        [ 0.48630074,  0.05139497,  0.18596786,  0.896042  ,  0.41696772,\n         -0.20431979, -0.7038673 ,  0.36588824, -0.585535  ,  0.08539825],\n        [ 0.20546024, -0.02902525,  0.08152312,  0.16051812, -0.21694328,\n          0.6073767 ,  0.48284286, -0.16513932, -1.0398079 , -0.61421204]],\n       dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=\n array([ 0.04355425, -0.06610215,  0.08786116,  0.2120888 , -0.3462229 ,\n         0.62077004, -0.19514523,  0.10470313,  0.2992508 ,  0.52460843],\n       dtype=float32)>,\n <tf.Variable 'dense_2/kernel:0' shape=(10, 10) dtype=float32, numpy=\n array([[ 0.691615  ,  0.5936723 ,  0.4093565 , -0.83925843, -0.7828725 ,\n          0.5158526 , -0.8820427 , -0.362975  , -0.2985989 , -1.1453624 ],\n        [ 0.7322963 ,  0.12142918, -0.90598   , -0.41163334, -0.10823423,\n          1.3478006 ,  0.40641645, -0.08116956, -1.1347287 ,  0.9229444 ],\n        [ 0.3813823 ,  1.0552502 ,  0.14324434, -1.1377708 , -1.2648126 ,\n         -0.42719477,  0.8903811 ,  0.5246431 ,  0.9269399 , -0.04617418],\n        [-0.572519  , -0.29894552,  0.50523305,  0.903135  , -0.6932652 ,\n         -0.6281929 , -1.6663195 ,  0.14311433, -0.48639065,  0.33960697],\n        [-1.0813228 ,  0.4305851 ,  0.60899955,  0.75019187, -0.5114089 ,\n          0.3226321 ,  1.0342126 ,  0.92938286, -0.8843498 , -1.4465424 ],\n        [ 0.3567711 , -1.529961  ,  1.0435911 , -0.11278864,  0.5032234 ,\n         -0.8372214 ,  0.22436325, -0.9246273 ,  0.6905704 ,  0.8758638 ],\n        [ 0.90710884, -0.55959314, -0.2709464 , -1.0995682 ,  0.896369  ,\n         -1.2732097 ,  0.80941993,  0.7357491 , -1.4183662 , -1.1733209 ],\n        [ 0.43626952, -1.726537  , -0.89481854,  1.1098286 , -1.1815541 ,\n          0.7447361 ,  0.5193724 , -0.24277532,  0.96256155,  0.02106609],\n        [-1.4233649 ,  0.0172324 , -1.1788158 , -1.2026457 ,  0.86268824,\n         -0.34861386, -1.2135496 ,  0.95533496, -0.15703778,  0.5632632 ],\n        [-1.5470405 ,  1.098367  , -0.65584636,  0.02195975,  1.2570457 ,\n          0.44238675, -0.27787274, -0.48028547,  0.72672844, -0.00695836]],\n       dtype=float32)>,\n <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32, numpy=\n array([ 0.44442645,  0.15744416,  0.17517023,  0.00568905, -0.04571148,\n        -0.3559922 , -0.21173881, -0.30403918,  0.30886495,  0.33038023],\n       dtype=float32)>]"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "a = model.history.on_epoch_end"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 49)                2450      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                500       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3060 (11.95 KB)\n",
      "Trainable params: 3060 (11.95 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'dense_1/kernel:0' shape=(49, 10) dtype=float32, numpy=\n array([[-0.11523119,  0.74989414,  0.4867244 ,  0.10672428,  0.70857257,\n         -0.15049213,  0.37308055,  0.2681915 , -0.42725733,  1.0608884 ],\n        [ 0.72385377, -1.247887  ,  0.5411213 ,  0.16477267,  0.3617893 ,\n         -0.2727737 ,  0.32806006, -0.01248247, -0.52733225,  0.3524414 ],\n        [-0.30899724,  0.71733034,  0.01521957, -0.83580655, -0.11362807,\n          0.16221197,  0.7763829 , -0.17205137,  0.5705083 ,  0.5456325 ],\n        [-0.8464556 ,  0.03504104,  0.17504364,  0.71113664,  0.46226028,\n          0.682038  ,  0.5079564 ,  0.12735783, -0.19697438, -0.5585122 ],\n        [ 0.2762116 ,  0.8439265 ,  0.33712485, -1.2095174 , -0.17419289,\n          0.13946502,  0.14711182,  0.4732441 ,  0.68180895,  0.5579827 ],\n        [ 0.2343097 ,  0.5049208 ,  0.6808184 ,  0.22736323,  0.14680737,\n          0.2668972 , -0.7924594 ,  0.51938015, -0.5769116 , -0.5299431 ],\n        [-0.30745247,  0.38900828,  0.3916732 ,  0.71308553,  0.9092859 ,\n         -0.10837077,  0.48933098,  0.06582701,  0.14245836, -0.99114233],\n        [-0.48213032, -0.06530164, -0.5694366 ,  0.5859642 , -0.1651227 ,\n          0.60471195,  0.16188103,  0.26677412,  0.801873  ,  0.6643758 ],\n        [-0.30054218, -0.3995869 , -0.41850019,  0.6935679 , -0.3564312 ,\n          0.31983015, -0.5630406 ,  0.69701904,  0.10232774,  0.59459573],\n        [ 0.28033063,  0.5230103 ,  0.3776445 , -0.09541139,  0.5209403 ,\n         -0.7235006 ,  0.33251187,  0.22997972, -0.63894886, -0.26621467],\n        [ 0.33804703,  0.27790993, -0.28754452,  0.9659055 , -0.7397116 ,\n          0.63369906, -0.77570146,  0.27308837,  0.07398554, -0.6770426 ],\n        [-0.3602435 , -0.41325352, -0.08695398,  0.6661703 ,  0.13399844,\n          0.94865805,  0.30693662,  0.20887323, -0.49811175, -0.34326363],\n        [-0.20528832, -0.6148676 ,  0.07618877,  0.7886893 ,  0.23688357,\n          0.58291507, -1.0544237 , -0.08156718,  0.21454899,  0.29202822],\n        [ 0.22476164,  0.33766967, -0.51246536,  0.7676785 ,  0.06082376,\n         -0.08186916, -0.75835615,  0.59792876, -0.09734324, -0.20358084],\n        [ 0.21230328, -0.7114051 ,  0.89480233, -0.30737728, -0.13447927,\n         -0.03783516,  0.2250414 ,  0.46495125, -0.09573676, -0.01798477],\n        [ 0.16831456,  0.7127604 , -0.6394222 ,  0.5345459 , -0.05751773,\n         -0.15718283,  0.04640725,  0.5403084 ,  0.63804346,  0.41172296],\n        [ 0.43975377,  0.2921067 ,  0.30036253,  0.9149723 , -0.2829437 ,\n          0.25812164,  0.36130685, -0.43561804,  0.35948738, -0.8480769 ],\n        [ 0.11690807, -0.17391479, -0.1193061 ,  0.25606304,  0.85500455,\n          0.806736  ,  0.6806784 , -0.8725962 , -0.26192048,  0.27706134],\n        [-0.04557033,  0.75939417, -1.0077293 ,  0.7426903 ,  0.02934753,\n         -0.3762126 , -1.0977196 , -0.40198445,  0.9433402 ,  0.80223984],\n        [ 0.39267638,  0.03729236, -0.2568747 ,  0.0645695 ,  0.603329  ,\n         -0.7343747 ,  0.6498765 ,  0.2491305 ,  0.46854198,  0.11620836],\n        [ 0.5318479 , -0.06337791,  0.07586922,  0.5872908 , -0.5942826 ,\n          0.6938231 , -0.01273923, -0.44888517,  0.4191366 , -0.2440634 ],\n        [ 0.48571622,  0.06809971, -0.01894148,  0.18291637, -0.49172258,\n          0.35008335,  0.23596175,  0.48289737, -0.6816155 , -1.0786813 ],\n        [ 0.4821134 ,  0.6243138 , -0.06493519, -0.20221773,  0.10038006,\n          0.5243329 , -0.3247746 ,  0.90287936,  0.76113   ,  0.6132198 ],\n        [-0.10610968, -0.40045708, -0.09783494,  0.4918939 ,  0.12723605,\n         -0.34161457,  0.45505932, -0.79961866,  0.84057164,  0.47064802],\n        [ 0.26973853, -0.01331284,  0.13912642, -0.50673777, -0.73590475,\n          1.0900517 ,  0.29115355,  0.13841848,  0.53821284, -0.1947915 ],\n        [ 0.15486519, -0.04832573,  0.76099324, -0.03450792, -0.0350772 ,\n         -0.0381346 ,  0.4184358 , -0.66018516,  0.89187783,  0.7109343 ],\n        [ 0.5403509 ,  0.273381  ,  0.33161214, -0.19784756,  0.84181505,\n          0.6673332 ,  0.11407552,  0.69461197, -0.2831134 ,  0.64888227],\n        [-0.21507095,  0.1997893 , -0.739687  ,  0.2433987 ,  0.00536519,\n         -0.12081501, -0.21883476,  0.6997855 , -0.06655935,  1.1693553 ],\n        [ 0.011591  ,  0.45651978,  0.22076721,  0.27364358,  0.06223401,\n         -0.11932169, -0.34949946,  0.9157648 , -1.1558144 ,  0.08681614],\n        [ 0.5141838 , -0.5591757 ,  0.20452335,  0.68330497,  1.124141  ,\n          0.10638725, -0.7285497 , -0.19856764,  0.44588318,  0.43037578],\n        [ 0.53010887, -0.72202617, -0.1430093 , -0.25117037, -0.28369206,\n          0.3533924 ,  1.087832  , -0.7416794 ,  0.4097122 ,  0.49623412],\n        [ 0.3018175 ,  0.27623802, -0.27902377, -0.21968329,  0.48065507,\n         -0.80129635,  0.37604922,  0.9295686 ,  0.08377022, -0.06890452],\n        [-0.29874447,  0.08192036, -0.38811356,  0.8843518 ,  0.33593237,\n          0.5988995 ,  0.24565189,  0.42627868,  0.30663094, -0.478902  ],\n        [-0.06994772,  1.0788432 ,  0.07267533,  0.30313197,  0.26564527,\n         -0.5441568 ,  0.8514332 , -0.61807317, -0.12676218, -0.7771933 ],\n        [ 0.29292372, -0.15816362,  0.61461514, -0.3129203 ,  0.7315723 ,\n         -0.5862373 ,  0.05627435,  0.17754522, -0.5010649 ,  0.43518054],\n        [ 0.15327127, -0.20313941,  0.12804106,  0.15758857, -0.3931847 ,\n          0.9457348 ,  0.11991976,  0.4639856 ,  0.1520161 ,  0.43069756],\n        [ 0.26239455, -0.7637088 ,  0.19472805,  0.2432851 , -0.01347096,\n          0.2957286 , -0.907485  , -0.19529094, -0.13798264,  0.00599864],\n        [ 0.8030082 ,  0.36491612, -0.13973442, -0.5464585 ,  0.55275744,\n          0.1957051 ,  0.6879884 , -0.56985545, -0.18342273,  0.3810998 ],\n        [ 0.50269955, -0.44216916,  0.21272345,  0.706942  ,  0.9695108 ,\n         -0.3114437 ,  0.21700181,  0.7464569 , -0.05929678, -0.28764036],\n        [ 0.16930515,  0.20706157,  0.57989365, -1.1375982 , -0.05144952,\n          0.48637524,  0.09601541, -0.12574247,  0.46961805,  0.58912826],\n        [ 0.5703397 ,  0.94003576,  0.50204873, -0.15406497, -0.29137245,\n         -0.539228  , -0.15488291,  0.25004017,  0.42799258,  0.39778394],\n        [ 0.06191554,  0.17992523,  0.58478904,  0.1280305 ,  0.4971792 ,\n          0.22753707, -1.3606417 , -0.39265662, -0.5572167 ,  0.8954716 ],\n        [ 0.18075   ,  0.66248816,  0.2547736 , -0.04026813, -0.20096856,\n         -0.32152328,  0.13340278, -0.6078787 ,  0.9456447 ,  0.06891274],\n        [-0.4160442 ,  0.2023628 ,  0.4711637 ,  0.5769162 ,  0.53377545,\n         -0.56334466, -0.1157601 ,  0.7643675 ,  0.467192  , -0.19027556],\n        [-0.6418563 , -0.7994236 , -0.21709314,  0.74357104,  0.35366026,\n          0.63773483,  0.40025243,  0.41125977, -0.10930327,  0.15087548],\n        [-0.12601341,  0.7987763 ,  0.07970108,  0.01005756, -0.39649636,\n         -0.27575552,  0.20341338,  0.5400827 ,  0.6492478 ,  0.71018106],\n        [ 0.0614295 ,  0.17297362,  0.29330668,  0.0853591 , -0.44798335,\n          0.45260903, -0.07757355,  0.90099204, -1.1447283 , -0.46496317],\n        [ 0.48630074,  0.05139497,  0.18596786,  0.896042  ,  0.41696772,\n         -0.20431979, -0.7038673 ,  0.36588824, -0.585535  ,  0.08539825],\n        [ 0.20546024, -0.02902525,  0.08152312,  0.16051812, -0.21694328,\n          0.6073767 ,  0.48284286, -0.16513932, -1.0398079 , -0.61421204]],\n       dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=\n array([ 0.04355425, -0.06610215,  0.08786116,  0.2120888 , -0.3462229 ,\n         0.62077004, -0.19514523,  0.10470313,  0.2992508 ,  0.52460843],\n       dtype=float32)>]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(49,), dtype=float32, numpy=\narray([-0.27706805,  0.25002897, -0.419819  ,  0.59392995,  0.1485502 ,\n       -0.12907892,  0.62336   ,  0.3395032 ,  0.20487075, -0.21127184,\n        0.4752211 ,  0.01133573, -0.6039726 , -0.03212717, -0.4878635 ,\n        0.6270028 ,  0.52504045, -0.18606345, -0.2667562 ,  0.5050743 ,\n       -0.01345157, -0.33759317,  0.36013448, -0.18635899, -0.17783159,\n        0.38438374,  0.09471858, -0.44952565, -0.45259142, -0.35597506,\n        0.3096208 , -0.10727202, -0.473725  , -0.41839957, -0.31727052,\n        0.27821097, -0.1781024 ,  0.30790317, -0.39417377,  0.383301  ,\n        0.01444338, -0.19953956,  0.077108  ,  0.40223277,  0.35875022,\n        0.27404806, -0.24312058, -0.39639348, -0.03478944], dtype=float32)>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights[0][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}